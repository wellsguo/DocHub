

### 顶帽去光差[LINK](http://www.opencv.org.cn/forum.php?mod=viewthread&tid=3284075)

```c++
// 顶帽去光差,radius为模板半径
Mat moveLightDiff(Mat src,int radius){
	Mat dst;
	Mat srcclone = src.clone();
	Mat mask = Mat::zeros(radius*2,radius*2,CV_8U);
	circle(mask,Point(radius,radius),radius,Scalar(255),-1);
	//顶帽
	erode(srcclone,srcclone,mask);
	dilate(srcclone,srcclone,mask);
	dst =  src - srcclone;
	return dst;

}
```
###### 算法来自于冈萨雷斯《数字图像处理教程》形态学篇章。完全按照教程实现，具备一定作用。


### 顶帽去光差[LINK](https://blog.csdn.net/hust_bochu_xuchao/article/details/54019994 )

如果一张图片中，光照不均匀，使用全局阈值时，就无法达到想要的阈值化效果。因此，不均匀光照的补偿算法研究，具有一定的意义。

当然，不均匀光照的补偿方法有很多，本文只是记录其中一种，具体效果如何，实际价值如何，还有待验证。希望看到此博文的读者，对不均匀光照有深入研究的，可以一起交流。

其主要思路为：

```c++

void unevenLightCompensate(Mat &image, int blockSize)
{
	if (image.channels() == 3) cvtColor(image, image, 7);
	double average = mean(image)[0];
	int rows_new = ceil(double(image.rows) / double(blockSize));
	int cols_new = ceil(double(image.cols) / double(blockSize));
	Mat blockImage;
	blockImage = Mat::zeros(rows_new, cols_new, CV_32FC1);
	for (int i = 0; i < rows_new; i++)
	{
		for (int j = 0; j < cols_new; j++)
		{
			int rowmin = i*blockSize;
			int rowmax = (i + 1)*blockSize;
			if (rowmax > image.rows) rowmax = image.rows;
			int colmin = j*blockSize;
			int colmax = (j + 1)*blockSize;
			if (colmax > image.cols) colmax = image.cols;
			Mat imageROI = image(Range(rowmin, rowmax), Range(colmin, colmax));
			double temaver = mean(imageROI)[0];
			blockImage.at<float>(i, j) = temaver;
		}
	}
	blockImage = blockImage - average;
	Mat blockImage2;
	resize(blockImage, blockImage2, image.size(), (0, 0), (0, 0), INTER_CUBIC);
	Mat image2;
	image.convertTo(image2, CV_32FC1);
	Mat dst = image2 - blockImage2;
	dst.convertTo(image, CV_8UC1);
}


```

> 效果图展示如下

![](https://img-blog.csdn.net/20170104155245957?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvaHVzdF9ib2NodV94dWNoYW8=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)



### 基于形态学开操作[LINK](https://answers.opencv.org/question/66125/object-detection-in-nonuniform-illumination/)

Morphology OPEN can detects bright structures larger that a given size. If you consider large structures as background you can use OPEN to detect background than remove it from the original image. This is same as to do MORPH_TOPHAT. Below is a simple function to do this.

This is the result on a simple image (source thanks to and result)

```c
/** @brief Remove non-uniform illumination using morphology
Morphology OPEN can detects bright structures larger that a given size.
If you consider large structures as background you can use OPEN
to detect background than remove it from the original image.
This is same as to do MORPH_TOPHAT.
@Param [in]src input image GRAY, BGR or BGRA.
With BGR(A) image this function uses Brightness from image HSV.
@Param [out]dst destination image. If alpha channel is present in src it will be cloned in dst
@Param minThickess size used by morphology operation to estimate background. Use small size to
enhance details flatting larger structures.
@c minThickess should be just larger than maximum thickness in objects you want to keep.
Example:
- Take thickest object, suppose is circle 100 * 100px
- Measure its maximum thickness let's say is 20px: In this case @c minThickess could be 20+5.
- If the circle is filled than thickness=diameter, consequently @c minThickess should be 100+5px
@Param restoreMean if true, the mean of input brightness will be restored in destination image.
if false, the destination brightness will be close to darker region of input image.
@Param [out]background if not NULL the removed background will be returned here.
This will be Mat(src.size(),CV_8UC1)
*/
void NonUniformIlluminationMorph(const cv::Mat &src, cv::Mat &dst, int minThickess = 5, bool restoreMean = true, cv::Mat *background=NULL)
{
    CV_Assert(minThickess >= 0);
    CV_Assert((src.type() == CV_8UC1) || (src.type() == CV_8UC3) || (src.type() == CV_8UC4));
    cv::Mat brightness, src_hsv;
    vector<cv::Mat> hsv_planes;

    // GET THE BRIGHTNESS
    if (src.type() == CV_8UC1)
        src.copyTo(brightness);
    else if (src.type() == CV_8UC3)
    {
        cv::cvtColor(src, src_hsv, cv::COLOR_BGR2HSV);
        cv::split(src_hsv, hsv_planes);
        brightness = hsv_planes[2];
    }
    else if (src.type() == CV_8UC4)
    {
        cv::cvtColor(src, src_hsv, cv::COLOR_BGRA2BGR);
        cv::cvtColor(src_hsv, src_hsv, cv::COLOR_BGR2HSV);
        cv::split(src_hsv, hsv_planes);
        brightness = hsv_planes[2];
    }

    //to restore previous brightness we need its current mean
    Scalar m;
    if (restoreMean)
        m = mean(brightness);

    // REMOVE THE BACKGROUND
    int size = minThickess / 2;
    Point anchor = Point(size, size);
    Mat element = getStructuringElement(MORPH_ELLIPSE, Size(2 * size + 1, 2 * size + 1), anchor);
    if (background != NULL) // to keep background we need to use MORPH_OPEN
    {
        //get the background
        cv::Mat bkg(brightness.size(), CV_8UC1);
        morphologyEx(brightness, bkg, MORPH_OPEN, element, anchor);
        //save the background
        (*background) = bkg;
        //remove the background
        brightness = brightness - bkg;
    }
    else //tophat(I)  <=> open(I) - I; 
    {
        //remove background
        morphologyEx(brightness, brightness, MORPH_TOPHAT, element, anchor);
    }

    // RESTORE PREVIOUS BRIGHTNESS MEAN
    if (restoreMean)
        brightness += m(0);

    // BUILD THE DESTINATION
    if (src.type() == CV_8UC1)
        dst = brightness;
    else if (src.type() == CV_8UC3)
    {
        merge(hsv_planes, dst);
        cvtColor(dst, dst, COLOR_HSV2BGR);
    }
    // restore alpha channel from source 
    else if (src.type() == CV_8UC4)
    {
        cv::Mat bgr;
        vector<cv::Mat> bgr_planes = { hsv_planes[0], hsv_planes[1], hsv_planes[2]};
        merge(bgr_planes, bgr);
        cvtColor(bgr, bgr, COLOR_HSV2BGR);

        int from_toA[] = { 0, 0, 1, 1, 2, 2 };
        src.copyTo(dst);
        cv::mixChannels(&bgr, 1, &dst, 1, from_toA, 3);
    }

    imshow("NonUniformIlluminationMorph:SRC", src);
    imshow("NonUniformIlluminationMorph:DST", dst);
    if ((background != NULL) && (!background->empty()))
        imshow("NonUniformIlluminationMorph:BKG", *background);
}
```
 Before | After
 -- | -- 
![](https://answers.opencv.org/upfiles/1449862093156643.jpg) | ![](https://answers.opencv.org/upfiles/14498621212180051.jpg)

```c
int main( int argc, char** argv )
{
    Mat z    = imread("1449862093156643.jpg",CV_LOAD_IMAGE_GRAYSCALE);

    Mat M = Mat_<double>(z.rows*z.cols,6);
    Mat I=Mat_<double>(z.rows*z.cols,1);
    for (int i=0;i<z.rows;i++)
        for (int j = 0; j < z.cols; j++)
        {
            double x=(j - z.cols / 2) / double(z.cols),y= (i - z.rows / 2) / double(z.rows);
            M.at<double>(i*z.cols+j, 0) = x*x;
            M.at<double>(i*z.cols+j, 1) = y*y;
            M.at<double>(i*z.cols+j, 2) = x*y;
            M.at<double>(i*z.cols+j, 3) = x;
            M.at<double>(i*z.cols+j, 4) = y;
            M.at<double>(i*z.cols+j, 5) = 1;
            I.at<double>(i*z.cols+j, 0) = z.at<uchar>(i,j);
        }
    SVD s(M);
    Mat q;
    s.backSubst(I,q);
    cout<<q;
    imshow("Orignal",z);
    cout<<q.at<double>(2,0);
    Mat background(z.rows,z.cols,CV_8UC1);
    for (int i=0;i<z.rows;i++)
        for (int j = 0; j < z.cols; j++)
        {
            double x=(j - z.cols / 2) / double(z.cols),y= (i - z.rows / 2) / double(z.rows);
            double quad=q.at<double>(0,0)*x*x+q.at<double>(1,0)*y*y+q.at<double>(2,0)*x*y;
            quad+=q.at<double>(3,0)*x+q.at<double>(4,0)*y+q.at<double>(5,0);
            background.at<uchar>(i,j) = saturate_cast<uchar>(quad);
        }
    imshow("Simulated background",background);
    Mat diff;
    absdiff(background,z,diff);
    double mind,maxd;
    minMaxLoc(diff,&mind,&maxd);
    imshow("background_original",diff*(256/(maxd-mind)));


    waitKey();
    return 0;
}
```

 Before | After
 -- | -- 
![](https://answers.opencv.org/upfiles/14503021212004002.jpg) | ![](https://answers.opencv.org/upfiles/1450302285378842.jpg)

### Detection of objects in nonuniform illumination in opencv C++ [LINK](https://stackoverflow.com/questions/31375948/detection-of-objects-in-nonuniform-illumination-in-opencv-c)

#### Question

I am performing feature detection in a video/live stream/image using OpenCV C++. The lighting condition varies in different parts of the video, leading to some parts getting ignored while transforming the RGB images to binary images.

The lighting condition in a particular portion of the video also changes over the course of the video. I tried the 'Histogram equalization' function, but it didn't help.

I got a working solution in MATLAB in the following link:

http://in.mathworks.com/help/images/examples/correcting-nonuniform-illumination.html

However, most of the functions used in the above link aren't available in OpenCV.

Can you suggest the alternative of this MATLAB code in OpenCV C++?

#### Answer

```c
void adaptiveThreshold(InputArray src, OutputArray dst, 
                      double maxValue, int adaptiveMethod, 
                      int thresholdType, int blockSize, double C);
```

[adaptiveThreshold](http://docs.opencv.org/modules/imgproc/doc/miscellaneous_transformations.html#adaptivethreshold) should be your first choice.

But here I report the "translation" from Matlab to OpenCV, so you can easily port your code. As you see, most of the functions are available both in Matlab and OpenCV.

```c
#include <opencv2\opencv.hpp>
using namespace cv;

int main()
{   
    // Step 1: Read Image
    Mat1b img = imread("path_to_image", IMREAD_GRAYSCALE);

    // Step 2: Use Morphological Opening to Estimate the Background
    Mat kernel = getStructuringElement(MORPH_ELLIPSE, Size(15,15));
    Mat1b background;
    morphologyEx(img, background, MORPH_OPEN, kernel);

    // Step 3: Subtract the Background Image from the Original Image
    Mat1b img2;
    absdiff(img, background, img2);

    // Step 4: Increase the Image Contrast
    // Don't needed it here, the equivalent would be  cv::equalizeHist

    // Step 5(1): Threshold the Image
    Mat1b bw;
    threshold(img2, bw, 50, 255, THRESH_BINARY);

    // Step 6: Identify Objects in the Image
    vector<vector<Point>> contours;
    findContours(bw.clone(), contours, CV_RETR_LIST, CV_CHAIN_APPROX_NONE);


    for(int i=0; i<contours.size(); ++i)
    {
        // Step 5(2): bwareaopen
        if(contours[i].size() > 50)
        {
            // Step 7: Examine One Object
            Mat1b object(bw.size(), uchar(0));
            drawContours(object, contours, i, Scalar(255), CV_FILLED);

            imshow("Single Object", object);
            waitKey();
        }
    }

    return 0;
}
```

### 其他方法

[局部二值化算法Niblack OpenCV实现](https://blog.csdn.net/fabulousli/article/details/52203263)

[sauvola算法实现图像二值化，解决光照不均匀](https://blog.csdn.net/cxf7394373/article/details/45155053)

[用于光照不均匀图片阈值化的Bernsen算法](https://blog.csdn.net/Leon_yy/article/details/80314380)

[不均匀光照文本图像的二值化](https://blog.csdn.net/u013162930/article/details/47755363)

[光照不均匀图像的灰度波动局部阈值分割](https://blog.csdn.net/u014328370/article/details/78337791)